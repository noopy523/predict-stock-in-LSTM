{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7b644c",
   "metadata": {},
   "source": [
    "導入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc75b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81e170",
   "metadata": {},
   "source": [
    "載入資料_訓練集：2014 年 ~ 2018 年的 TSMC（共 1231 天）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c02cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>8618.599609</td>\n",
       "      <td>8632.809570</td>\n",
       "      <td>8587.540039</td>\n",
       "      <td>8612.540039</td>\n",
       "      <td>8612.507813</td>\n",
       "      <td>2537600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>8584.740234</td>\n",
       "      <td>8584.740234</td>\n",
       "      <td>8537.860352</td>\n",
       "      <td>8546.540039</td>\n",
       "      <td>8546.507813</td>\n",
       "      <td>2539700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>8553.000000</td>\n",
       "      <td>8568.240234</td>\n",
       "      <td>8488.639648</td>\n",
       "      <td>8500.009766</td>\n",
       "      <td>8499.977539</td>\n",
       "      <td>2640100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>8515.360352</td>\n",
       "      <td>8547.190430</td>\n",
       "      <td>8512.299805</td>\n",
       "      <td>8512.299805</td>\n",
       "      <td>8512.267578</td>\n",
       "      <td>2598900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>8548.610352</td>\n",
       "      <td>8587.080078</td>\n",
       "      <td>8548.610352</td>\n",
       "      <td>8556.009766</td>\n",
       "      <td>8555.977539</td>\n",
       "      <td>3206300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         Open         High          Low        Close  \\\n",
       "0  2014-01-02  8618.599609  8632.809570  8587.540039  8612.540039   \n",
       "1  2014-01-03  8584.740234  8584.740234  8537.860352  8546.540039   \n",
       "2  2014-01-06  8553.000000  8568.240234  8488.639648  8500.009766   \n",
       "3  2014-01-07  8515.360352  8547.190430  8512.299805  8512.299805   \n",
       "4  2014-01-08  8548.610352  8587.080078  8548.610352  8556.009766   \n",
       "\n",
       "     Adj Close     Volume  \n",
       "0  8612.507813  2537600.0  \n",
       "1  8546.507813  2539700.0  \n",
       "2  8499.977539  2640100.0  \n",
       "3  8512.267578  2598900.0  \n",
       "4  8555.977539  3206300.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = pd.read_csv(\"台指數/台灣加權指數2014-2018.csv\")\n",
    "dataset_train = dataset_train.fillna(0) #缺值得都補 0，等等int轉換才不會有問題\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2203b53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8618.599609],\n",
       "       [8584.740234],\n",
       "       [8553.      ],\n",
       "       ...,\n",
       "       [9544.870117],\n",
       "       [9555.009766],\n",
       "       [9649.969727]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將資料顯示為(資料長度,1) 等同reshape(-1,1)\n",
    "training_set = dataset_train.iloc[: ,4:5].values\n",
    "#training_set = dataset_train.iloc[: ,1:2].values\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1120d96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n",
      "[[0.76534751]\n",
      " [0.75948247]\n",
      " [0.75534759]\n",
      " ...\n",
      " [0.84234402]\n",
      " [0.85679064]\n",
      " [0.86441969]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#做 Normalization，將資料壓縮在 [0,1] 之間\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "print(sc)\n",
    "\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "print(training_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d16273fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第i天之前的股價\n",
      "[[0.76534751]\n",
      " [0.75948247]\n",
      " [0.75534759]\n",
      " [0.75643973]\n",
      " [0.76032399]\n",
      " [0.75665122]\n",
      " [0.75795485]\n",
      " [0.76122956]\n",
      " [0.75962462]\n",
      " [0.76445974]]\n",
      "第i天股價\n",
      "0.7653093307193404\n"
     ]
    }
   ],
   "source": [
    "X_train = []   #預測點的前 10 天的資料\n",
    "y_train = []   #預測點\n",
    "for i in range(10, len(training_set)):  # 1231 是訓練集總數 / 2014~2018總天數\n",
    "    X_train.append(training_set_scaled[i-10:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)  # 轉成numpy array的格式，以利輸入 RNN\n",
    "\n",
    "#因為現在 X_train 是 2-dimension，\n",
    "#將它 reshape 成 3-dimension: [stock prices, timesteps, indicators]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "print('第i天之前的股價')\n",
    "print(X_train[0])\n",
    "print('第i天股價')\n",
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c9cd4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Keras libraries and packages\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout,BatchNormalization\n",
    "\n",
    "# Initialising the RNN\n",
    "keras.backend.clear_session()\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e5b7e",
   "metadata": {},
   "source": [
    "# 搭建 LSTM layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8eb2d6",
   "metadata": {},
   "source": [
    "units: 神經元的數目 (setting 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4abd848",
   "metadata": {},
   "source": [
    "第一層的 LSTM Layer 記得要設定input_shape參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d98bfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train.shape[1], 1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6096ef9",
   "metadata": {},
   "source": [
    "搭配使用dropout，這裡設為 0.2(Float between 0 and 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914d76a1",
   "metadata": {},
   "source": [
    "由於這邊的第四層 LSTM Layer 即將跟 Ouput Layer 做連接，因此注意這邊的 return_sequences 設為預設值 False （也就是不用寫上 return_sequences）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b85916",
   "metadata": {},
   "source": [
    "用了 2層 LSTM，之前4曾跑不出來是缺值忘了補0，轉int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81b2a93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation,activation use relu functio\n",
    "regressor.add(LSTM(units = 50,activation=\"relu\", return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "#regressor.add(LSTM(units = 50,activation=\"relu\", return_sequences = True))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "#regressor.add(LSTM(units = 50, activation=\"relu\",return_sequences = True))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, activation=\"relu\"))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer setting 1\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa9f8b",
   "metadata": {},
   "source": [
    "# Compiling & Fitting LSTM model\n",
    "optimizer: 選擇 Adam \\\\\\\n",
    "loss: 使用 MSE \\\\\\\n",
    "learning rate(lr) :0.001 \\\\\\\n",
    "epochs :100 \\\\\\\n",
    "batch size:32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605e681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.3294\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0247\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0219\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0181\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0181\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0164\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0147\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0162\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0144\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0138\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0131\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0129\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0132\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0141\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0126\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0125\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0128\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0122\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0129\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0125\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0120\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0120\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0121\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0118\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0128\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0112\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0122\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0112\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0124\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.0114\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0115\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0117\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0111\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0120\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0120\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0113\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0111\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0115\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0106\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.0104\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.0113\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.0111\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.0110\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.0112: 0s - loss: 0.01\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.0109\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.0100\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.0106\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.0103\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.0096\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.0101\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0090\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0094\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0098\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0091\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.0099\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0093\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0093\n",
      "Epoch 58/100\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 0.0074"
     ]
    }
   ],
   "source": [
    "# Compiling\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "regressor.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "\n",
    "# 進行訓練\n",
    "history = regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)\n",
    "plt.title('train_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot( history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaaded1",
   "metadata": {},
   "source": [
    "# 預測步驟"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704434d8",
   "metadata": {},
   "source": [
    "取測試集中 2019 年的股票資料（真實）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('台指數/台灣加權指數2019-2020.csv', usecols=[4], engine='python')\n",
    "dataset_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('台指數/台灣加權指數2019-2020.csv')\n",
    "#real_stock_price = dataset_test.iloc[:, 4:5].values\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa739c5",
   "metadata": {},
   "source": [
    "取模型所預測的 2019 年股票資料（預測）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35178ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total = pd.concat((dataset_train['Close'], dataset_test['Close']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs) # Feature Scaling\n",
    "\n",
    "X_test = []\n",
    "for i in range(60, 80):  # timesteps一樣60； 80 = 先前的60天資料+2017年的20天資料\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))  # Reshape 成 3-dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83483745",
   "metadata": {},
   "source": [
    "start predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2eedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)  # to get the original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee41ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real TSEC Stock Price')  # 紅線表示真實股價\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted TSEC Stock Price')  # 藍線表示預測股價\n",
    "plt.title('TSEC Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('TSEC Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148733c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf23",
   "language": "python",
   "name": "tf23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
